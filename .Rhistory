boot.ci(results, conf = 0.99, type=c("norm"), index=1) # intercept
var.calc
a
b
VaRhistorical(-lossVector, prob = .01)
a1
b1
boot.ci(results, conf = 0.95, type=c("norm"), index=1) # intercept
EShistorical <- function(returnVector, indices, prob=.01,
notional=1, digits=4)
{
if(prob > .5) prob <- 1 - prob
d <- returnVector[indices]
v <- quantile(d, prob)
ans <- -mean(d[d <= v]) * notional
return(signif(ans, digits=digits))
}
results <- boot(data=-lossVector, statistic=EShistorical,
R=1000)
# view results
results
boot.ci(results, conf = 0.99, type=c("norm"), index=1) # intercept
logit.train.auc <- performance(glm.train.pred, measure="auc")
library(glmnet)
grid=10^seq(2,-2,length=100)
glm_train_indep <- train_pruned[,glmIndepVars]
glm_test_indep <- test_pruned[,glmIndepVars]
glm_train_indep$is504 <- glm_train_indep$DeliveryMethod == "504"
glm_train_indep$isPCLP <- glm_train_indep$DeliveryMethod == "PCLP"
glm_train_indep$isALP <- glm_train_indep$DeliveryMethod == "ALP"
glm_train_indep$isRefi <- glm_train_indep$DeliveryMethod == "504REFI"
n_occur_temp <- data.frame(table(glm_train_indep$DeliveryMethod))
glm_train_indep$isIndiv <- glm_train_indep$BusinessType == "INDIVIDUAL"
glm_train_indep$isPartnership <- glm_train_indep$BusinessType == "PARTNERSHIP"
glm_train_indep$isCorp <- glm_train_indep$BusinessType == "CORPORATION"
glm_test_indep$is504 <- glm_test_indep$DeliveryMethod == "504"
glm_test_indep$isPCLP <- glm_test_indep$DeliveryMethod == "PCLP"
glm_test_indep$isALP <- glm_test_indep$DeliveryMethod == "ALP"
glm_test_indep$isRefi <- glm_test_indep$DeliveryMethod == "504REFI"
glm_test_indep$isIndiv <- glm_test_indep$BusinessType == "INDIVIDUAL"
glm_test_indep$isPartnership <- glm_test_indep$BusinessType == "PARTNERSHIP"
glm_test_indep$isCorp <- glm_test_indep$BusinessType == "CORPORATION"
#take out non-numeric columns
boot_drops <- c("DeliveryMethod","BusinessType")
glm_train_indep <- glm_train_indep[,!(names(glm_train_indep) %in% boot_drops)]
glm_test_indep <- glm_test_indep[,!(names(glm_test_indep) %in% boot_drops)]
glm.fit <- glm(defaulted~., data = glm_train_indep, family = binomial)
glm.probs <- predict.glm(glm.fit, newdata = glm_train_indep, type = "response")
glm.train.pred <- prediction(glm.probs, train_pruned$defaulted)
glm.probs.test <- predict.glm(glm.fit, newdata=glm_test_indep, type="response")
glm.test.pred <- prediction(glm.probs.test, test_pruned$defaulted)
logit.train.auc <- performance(glm.train.pred, measure="auc")
logit.test.auc <- performance(glm.test.pred, measure = "auc")
logit.test.auc@y.values
logit.train.auc@y.values
defaults.glm <- glm(defaulted ~ ., glm_train_indep, family="binomial")
lasso.train.auc@y.values
lasso.train.auc <- performance(train.pred, measure = "auc")
test.phat <- predict(lasso.cv,
newx=data.matrix(test_indep),
s="lambda.1se",
type = "response")
test.pred <- prediction(test.phat, test_pruned$defaulted)
train.phat <- predict(lasso.cv, newx=data.matrix(train_indep),s="lambda.1se",type="response")
train.pred <- prediction(train.phat, train_pruned$defaulted)
test.roc <- performance(test.pred, measure = "tpr", x.measure = "fpr")
train.roc <- performance(train.pred, measure="tpr", x.measure="fpr")
plot(test.roc,colorize=FALSE, col="red", main="ROC Curve - Logistic Regression w/ Lasso")
plot(train.roc,colorize=FALSE, col="black", add=TRUE)
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend("bottomright", cex=0.75, c("In-sample","Out-of-sample"), lty=c(1,1), lwd=c(2.5,2.5), col=c("black","red"))
lasso.train.auc <- performance(train.pred, measure = "auc")
lasso.train.auc@y.values
lasso.test.auc <- performance(test.pred, measure = "auc")
lasso.test.auc@y.values
plot(lossGivenDefault)
train_chargeoff_pred <- predict(lossGivenDefault, newx=data.matrix(train_nonzero_indep), s = "lambda.1se")
train_chargeoff_error <- mean((train_chargeoff_pred - train_ChargeApproveRatio)^2)
summary(glm.fit)
plot(lossGivenDefault, main="L1-Regularized Linear Regression:\nChargeoff/Approval Ratio")
plot(lossGivenDefault)
qqnorm(log(mydata$GrossApproval))
qqnorm((mydata$GrossApproval))
mydata <- read.csv("SBA_Loan_data.csv")
# Making new column for default status
mydata$defaulted <- mydata$LoanStatus == "CHGOFF"
#take out status=EXEMPT and status=CANCLD
mydata <- subset(mydata, LoanStatus!="EXEMPT"&LoanStatus!="CANCLD"&!is.na(BusinessType))
#find loans where term is (not) yearly
mydata$TermYearly <- mydata$TermInMonths%%12 == 0
#find duplicate borrowers
n_occur <- data.frame(table(mydata$BorrName))
n_occur <- n_occur[n_occur$Freq > 1,]
mydata$IsDuplicateBorrower <- mydata$BorrName %in% n_occur[,1]
#Merge with Housing Price Index data from FHFA (works!)
hpi_data <- read.table("HPI_PO_state.txt", header=TRUE, sep="\t")
names(hpi_data)[names(hpi_data)=="index_sa"] <- "HousingPriceIndex"
hpi.badcols <- c("Warning","index_nsa", "qtr")
hpi_data <- subset(hpi_data, qtr==4)
hpi_data <- hpi_data[,-which(names(hpi_data) %in% hpi.badcols)]
mydata <- merge(x=mydata, y=hpi_data, by.x=c("BorrState","ApprovalFiscalYear"), by.y=c("state","yr"))
#Merge with State Unemployment Rate data from BLS
unemp_data <- read.table("State_level_unemployment_rate_Monthly.txt", header=TRUE, sep="\t")
unemp_data_subset <- unemp_data[grep("-12-01", unemp_data$DATE), ]
unemp_data_subset$DATE <- gsub("-12-01", "", unemp_data_subset$DATE)
names(unemp_data_subset) <- gsub("UR","",names(unemp_data_subset))
#splice unemployment rate data into mydata table (works)
unemp_data_subset <- unemp_data_subset[,!(names(unemp_data_subset) %in% c("DATE"))]
temp_table <- data.frame(matrix(NA, nrow = 2000, ncol = 3))
i = 1
for(yr in 1:nrow(unemp_data_subset)) {
for(st in names(unemp_data_subset)) {
temp_table[i, ] = c(yr+1975,st,unemp_data_subset[yr,st])
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "UnemploymentRate"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$UnemploymentRate <- as.numeric(mydata$UnemploymentRate)
#Merge with Federal Funds Rate data from St. Louis Fed (works!)
fedfunds_data <- read.csv("fredgraph.csv")
fedfunds_data_subset <- fedfunds_data[grep("-12-01", fedfunds_data$observation_date),]
fedfunds_data_subset$observation_date <- gsub("-12-01", "", fedfunds_data_subset$observation_date)
mydata <- merge(x=mydata, y=fedfunds_data_subset, by.x="ApprovalFiscalYear", by.y="observation_date")
#Merge with Median Household Income data from US Census Bureau (works!)
household_income_data <- read.csv("medianhhincome.csv", header=TRUE)
names(household_income_data) <- gsub("X","",names(household_income_data))
household_mat <- as.matrix(household_income_data)
temp_table <- data.frame(matrix(NA, nrow = 1250, ncol = 3))
i = 1
for(yr in 2:ncol(household_mat)) {
for(st in 1:nrow(household_mat)-1) {
temp_table[i, ] = c(2016-yr,household_mat[st,1],as.integer(gsub(",","",household_mat[st,yr])))
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "HouseholdIncome"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$HouseholdIncome <- as.numeric(mydata$HouseholdIncome)
#Merge data with S&P returns, VIX level, 3-month and 10-month T-bill
sp_data <- read.csv("SP-data.csv")
mydata <- merge(x=mydata, y=sp_data, by.x="ApprovalFiscalYear", by.y="Year")
#Merge data with additional data from Cameron's research:
addl_data <- read.csv("Addl_Data_Selected.csv")
addl_data$Euro.USD <- NULL
addl_data$X10.yrSwap <- NULL
addl_data$Case.Shiller <- NULL
##CREATE DUMMY VARIABLES TO INDICATE MISSING DATA. OR ELSE
addl_data$StockMktTurnover_China <- NULL
addl_data$BAML_HY_Adj_Sprd <- NULL
addl_data$DisposableIncome <- NULL
mydata <- merge(x=mydata, y=addl_data, by.x="ApprovalFiscalYear", by.y="Year")
mydata$HousingPriceIndex <- mydata$HousingPriceIndex - mean(mydata$HousingPriceIndex)
mydata$HousingPriceIndex <- mydata$HousingPriceIndex / sd(mydata$HousingPriceIndex)
mydata$HouseholdIncome <- mydata$HouseholdIncome - mean(mydata$HouseholdIncome)
mydata$HouseholdIncome <- mydata$HouseholdIncome / sd(mydata$HouseholdIncome)
mydata$PublicDebt.GDP <- mydata$PublicDebt.GDP - mean(mydata$PublicDebt.GDP)
mydata$PublicDebt.GDP <- mydata$PublicDebt.GDP / sd(mydata$PublicDebt.GDP)
mydata$IndustrialProduction <- mydata$IndustrialProduction - mean(mydata$IndustrialProduction)
mydata$IndustrialProduction <- mydata$IndustrialProduction / sd(mydata$IndustrialProduction)
mydata$CPI_Index <- mydata$CPI_Index - mean(mydata$CPI_Index)
mydata$CPI_Index <- mydata$CPI_Index / sd(mydata$CPI_Index)
mydata$GrossApproval <- log(mydata$GrossApproval)
mydata$GrossApproval <- mydata$GrossApproval - mean(mydata$GrossApproval)
mydata$GrossApproval <- mydata$GrossApproval / sd(mydata$GrossApproval)
setwd("m-e246")
setwd("ms-e246")
mydata <- read.csv("SBA_Loan_data.csv")
# Making new column for default status
mydata$defaulted <- mydata$LoanStatus == "CHGOFF"
#take out status=EXEMPT and status=CANCLD
mydata <- subset(mydata, LoanStatus!="EXEMPT"&LoanStatus!="CANCLD"&!is.na(BusinessType))
#find loans where term is (not) yearly
mydata$TermYearly <- mydata$TermInMonths%%12 == 0
#find duplicate borrowers
n_occur <- data.frame(table(mydata$BorrName))
n_occur <- n_occur[n_occur$Freq > 1,]
mydata$IsDuplicateBorrower <- mydata$BorrName %in% n_occur[,1]
#Merge with Housing Price Index data from FHFA (works!)
hpi_data <- read.table("HPI_PO_state.txt", header=TRUE, sep="\t")
names(hpi_data)[names(hpi_data)=="index_sa"] <- "HousingPriceIndex"
hpi.badcols <- c("Warning","index_nsa", "qtr")
hpi_data <- subset(hpi_data, qtr==4)
hpi_data <- hpi_data[,-which(names(hpi_data) %in% hpi.badcols)]
mydata <- merge(x=mydata, y=hpi_data, by.x=c("BorrState","ApprovalFiscalYear"), by.y=c("state","yr"))
#Merge with State Unemployment Rate data from BLS
unemp_data <- read.table("State_level_unemployment_rate_Monthly.txt", header=TRUE, sep="\t")
unemp_data_subset <- unemp_data[grep("-12-01", unemp_data$DATE), ]
unemp_data_subset$DATE <- gsub("-12-01", "", unemp_data_subset$DATE)
names(unemp_data_subset) <- gsub("UR","",names(unemp_data_subset))
#splice unemployment rate data into mydata table (works)
unemp_data_subset <- unemp_data_subset[,!(names(unemp_data_subset) %in% c("DATE"))]
temp_table <- data.frame(matrix(NA, nrow = 2000, ncol = 3))
i = 1
for(yr in 1:nrow(unemp_data_subset)) {
for(st in names(unemp_data_subset)) {
temp_table[i, ] = c(yr+1975,st,unemp_data_subset[yr,st])
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "UnemploymentRate"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$UnemploymentRate <- as.numeric(mydata$UnemploymentRate)
#Merge with Federal Funds Rate data from St. Louis Fed (works!)
fedfunds_data <- read.csv("fredgraph.csv")
fedfunds_data_subset <- fedfunds_data[grep("-12-01", fedfunds_data$observation_date),]
fedfunds_data_subset$observation_date <- gsub("-12-01", "", fedfunds_data_subset$observation_date)
mydata <- merge(x=mydata, y=fedfunds_data_subset, by.x="ApprovalFiscalYear", by.y="observation_date")
#Merge with Median Household Income data from US Census Bureau (works!)
household_income_data <- read.csv("medianhhincome.csv", header=TRUE)
names(household_income_data) <- gsub("X","",names(household_income_data))
household_mat <- as.matrix(household_income_data)
temp_table <- data.frame(matrix(NA, nrow = 1250, ncol = 3))
i = 1
for(yr in 2:ncol(household_mat)) {
for(st in 1:nrow(household_mat)-1) {
temp_table[i, ] = c(2016-yr,household_mat[st,1],as.integer(gsub(",","",household_mat[st,yr])))
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "HouseholdIncome"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$HouseholdIncome <- as.numeric(mydata$HouseholdIncome)
#Merge data with S&P returns, VIX level, 3-month and 10-month T-bill
sp_data <- read.csv("SP-data.csv")
mydata <- merge(x=mydata, y=sp_data, by.x="ApprovalFiscalYear", by.y="Year")
#Merge data with additional data from Cameron's research:
addl_data <- read.csv("Addl_Data_Selected.csv")
addl_data$Euro.USD <- NULL
addl_data$X10.yrSwap <- NULL
addl_data$Case.Shiller <- NULL
##CREATE DUMMY VARIABLES TO INDICATE MISSING DATA. OR ELSE
addl_data$StockMktTurnover_China <- NULL
addl_data$BAML_HY_Adj_Sprd <- NULL
addl_data$DisposableIncome <- NULL
mydata <- merge(x=mydata, y=addl_data, by.x="ApprovalFiscalYear", by.y="Year")
mydata$HousingPriceIndex <- mydata$HousingPriceIndex - mean(mydata$HousingPriceIndex)
mydata$HousingPriceIndex <- mydata$HousingPriceIndex / sd(mydata$HousingPriceIndex)
mydata$HouseholdIncome <- mydata$HouseholdIncome - mean(mydata$HouseholdIncome)
mydata$HouseholdIncome <- mydata$HouseholdIncome / sd(mydata$HouseholdIncome)
mydata$PublicDebt.GDP <- mydata$PublicDebt.GDP - mean(mydata$PublicDebt.GDP)
mydata$PublicDebt.GDP <- mydata$PublicDebt.GDP / sd(mydata$PublicDebt.GDP)
mydata$IndustrialProduction <- mydata$IndustrialProduction - mean(mydata$IndustrialProduction)
mydata$IndustrialProduction <- mydata$IndustrialProduction / sd(mydata$IndustrialProduction)
mydata$CPI_Index <- mydata$CPI_Index - mean(mydata$CPI_Index)
mydata$CPI_Index <- mydata$CPI_Index / sd(mydata$CPI_Index)
mydata$GrossApproval <- log(mydata$GrossApproval)
mydata$GrossApproval <- mydata$GrossApproval - mean(mydata$GrossApproval)
mydata$GrossApproval <- mydata$GrossApproval / sd(mydata$GrossApproval)
set.seed(100)
mixed.set <- mydata[sample(nrow(mydata)),]
train <- mixed.set[1:38346,]
test <- mixed.set[38346:53352,]
#uninteresting variables not used in our model analysis
drops <- c("Program", "BorrName","BorrStreet","BorrCity","BorrZip","CDC_Name","CDC_Street","CDC_City","CDC_Zip","ThirdPartyLender_Name","ThirdPartyLender_City","ThirdPartyLender_State","ThirdPartyDollars","Delivery Method","ProjectCounty","ApprovalDate","ChargeOffDate","NaicsDescription","BorrState","CDC_State","ProjectState","LoanStatus","subpgmdesc","NaicsCode","InitialInterestRate")
train_pruned <- train[,!(names(train) %in% drops)]
test_pruned <- test[,!(names(test) %in% drops)]
library(glmnet)
library(ROCR)
grid=10^seq(2,-2,length=100)
#set up logistic regression
glmIndepVars <- !(names(train_pruned) %in% c("GrossChargeOffAmount"))
glm_train_indep <- train_pruned[,glmIndepVars]
glm_test_indep <- test_pruned[,glmIndepVars]
#make indicator variables for delivery method, business type
#using glm_train_indep
glm_train_indep$is504 <- glm_train_indep$DeliveryMethod == "504"
glm_train_indep$isPCLP <- glm_train_indep$DeliveryMethod == "PCLP"
glm_train_indep$isALP <- glm_train_indep$DeliveryMethod == "ALP"
glm_train_indep$isRefi <- glm_train_indep$DeliveryMethod == "504REFI"
n_occur_temp <- data.frame(table(glm_train_indep$DeliveryMethod))
glm_train_indep$isIndiv <- glm_train_indep$BusinessType == "INDIVIDUAL"
glm_train_indep$isPartnership <- glm_train_indep$BusinessType == "PARTNERSHIP"
glm_train_indep$isCorp <- glm_train_indep$BusinessType == "CORPORATION"
glm_test_indep$is504 <- glm_test_indep$DeliveryMethod == "504"
glm_test_indep$isPCLP <- glm_test_indep$DeliveryMethod == "PCLP"
glm_test_indep$isALP <- glm_test_indep$DeliveryMethod == "ALP"
glm_test_indep$isRefi <- glm_test_indep$DeliveryMethod == "504REFI"
glm_test_indep$isIndiv <- glm_test_indep$BusinessType == "INDIVIDUAL"
glm_test_indep$isPartnership <- glm_test_indep$BusinessType == "PARTNERSHIP"
glm_test_indep$isCorp <- glm_test_indep$BusinessType == "CORPORATION"
#take out non-numeric columns
boot_drops <- c("DeliveryMethod","BusinessType")
glm_train_indep <- glm_train_indep[,!(names(glm_train_indep) %in% boot_drops)]
glm_test_indep <- glm_test_indep[,!(names(glm_test_indep) %in% boot_drops)]
glm.fit <- glm(defaulted~., data = glm_train_indep, family = binomial)
glm.probs <- predict.glm(glm.fit, newdata = glm_train_indep, type = "response")
glm.train.pred <- prediction(glm.probs, train_pruned$defaulted)
glm.probs.test <- predict.glm(glm.fit, newdata=glm_test_indep, type="response")
glm.test.pred <- prediction(glm.probs.test, test_pruned$defaulted)
# get statistics on the model
#roc
glm.train.perf <- performance(glm.train.pred, measure = "tpr", x.measure = "fpr")
glm.test.perf <- performance(glm.test.pred, measure="tpr", x.measure="fpr")
plot(glm.train.perf,colorize=FALSE, col="black", main="ROC Curve - Logistic Regression") # plot ROC curve
plot(glm.test.perf,colorize=FALSE, col="red", add=TRUE)
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend("bottomright", cex=0.75, c("In-sample","Out-of-sample"), lty=c(1,1), lwd=c(2.5,2.5), col=c("black","red"))
#accuracy
glm.train.err <- performance(glm.train.pred, measure = "err")
plot(glm.train.err, col = "black", xlim=c(0,.5), xlab="Threshold", main="Error Rate vs Threshold - Logistic Regression (train)")
glm.train.fpr <- performance(glm.train.pred, measure = "fpr")
plot(glm.train.fpr, add=TRUE, col = "red")
glm.train.fnr <- performance(glm.train.pred, measure = "fnr")
plot(glm.train.fnr, add=TRUE, col = "blue")
legend("topright", cex = 0.75,
c("Total Error Rate","False Positive Rate","False Negative Rate"),
lty=c(1,1,1), # gives the legend appropriate symbols (lines)
lwd=c(2.5,2.5,2.5),col=c("black","red","blue"))
glm.test.err <- performance(glm.test.pred, measure = "err")
plot(glm.test.err, col = "black", xlim=c(0,.5), xlab = "Threshold", main="Error Rate vs Threshold - Logistic Regression (test)")
glm.test.fpr <- performance(glm.test.pred, measure = "fpr")
plot(glm.test.fpr, add=TRUE, col = "red", lty = 3)
glm.test.fnr <- performance(glm.test.pred, measure = "fnr")
plot(glm.test.fnr, add=TRUE, col = "blue", lty=2)
legend("topright", cex = .75,
c("Total Error Rate","False Positive Rate","False Negative Rate"),
lty=c(1,1,1), # gives the legend appropriate symbols (lines)
lwd=c(2.5,2.5,2.5),col=c("black","red","blue"))
#AUC
logit.train.auc <- performance(glm.train.pred, measure="auc")
logit.test.auc <- performance(glm.test.pred, measure = "auc")
logit.test.auc@y.values
logit.train.auc@y.values
indepVars <- !(names(train_pruned) %in% c("defaulted", "GrossChargeOffAmount"))
train_indep <- train_pruned[, indepVars]
test_indep <- test_pruned[, indepVars]
all_glmnet_indep <- rbind(train_indep, test_indep)
# Control randomness in Lasso CV fit
set.seed(2123)
# Produce a Lasso CV fit
lasso.cv <- cv.glmnet(x=data.matrix(train_indep), y=train_pruned$defaulted, family = "binomial")
#plot(lasso.cv, main="L1-Regularized Logistic Regression")\
plot(lasso.cv)
test.predict <- predict(lasso.cv,
newx=data.matrix(test_indep),
s="lambda.1se",
type = "response")
test.pred <- prediction(test.predict, test_pruned$defaulted)
train.predict <- predict(lasso.cv, newx=data.matrix(train_indep),s="lambda.1se",type="response")
train.pred <- prediction(train.predict, train_pruned$defaulted)
# Obtain performance statistics
# Plot ROC
test.roc <- performance(test.pred, measure = "tpr", x.measure = "fpr")
train.roc <- performance(train.pred, measure="tpr", x.measure="fpr")
plot(test.roc,colorize=FALSE, col="red", main="ROC Curve - Logistic Regression w/ Lasso")
plot(train.roc,colorize=FALSE, col="black", add=TRUE)
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend("bottomright", cex=0.75, c("In-sample","Out-of-sample"), lty=c(1,1), lwd=c(2.5,2.5), col=c("black","red"))
lasso.train.auc <- performance(train.pred, measure = "auc")
lasso.train.auc@y.values
lasso.test.auc <- performance(test.pred, measure = "auc")
lasso.test.auc@y.values
library(glmnet)
library(survival)
drops_surv <- c("Program", "BorrName","BorrStreet","BorrCity","BorrZip","CDC_Name","CDC_Street","CDC_City","CDC_Zip","ThirdPartyLender_Name","ThirdPartyLender_City","ThirdPartyLender_State","ThirdPartyDollars","Delivery Method","ProjectCounty","NaicsDescription","BorrState","CDC_State","ProjectState","LoanStatus","subpgmdesc","NaicsCode","InitialInterestRate")
train_pruned_surv <- train[,!(names(train) %in% drops_surv)]
test_pruned_surv <- test[,!(names(test) %in% drops_surv)]
#get independent variables
indep_surv_vars = !(names(train_pruned_surv) %in% c("ApprovalFiscalYear", "ApprovalDate", "ChargeOffDate", "defaulted", "status", "EndDate", "YearsBeforeDefault"))
train_surv_indep <- train_pruned_surv[,indep_surv_vars]
test_surv_indep <- test_pruned_surv[,indep_surv_vars]
#format the data for the the survival analysis
train_pruned_surv$EndDate <- as.Date(train_pruned_surv$ChargeOffDate, format="%m/%d/%y")
train_pruned_surv$status <- train_pruned_surv$defaulted
train_pruned_surv$EndDate[which(train_pruned_surv$status == 0)] <- as.Date('12/31/14', format="%m/%d/%y")
train_pruned_surv$YearsBeforeDefault <- difftime(train_pruned_surv$EndDate,as.Date(as.character(train_pruned_surv$ApprovalDate), format="%m/%d/%y"), units = "days") / 365
test_pruned_surv$EndDate <- as.Date(test_pruned_surv$ChargeOffDate, format="%m/%d/%y")
test_pruned_surv$status <- test_pruned_surv$defaulted
test_pruned_surv$EndDate[which(test_pruned_surv$status == 0)] <- as.Date('12/31/14', format="%m/%d/%y")
test_pruned_surv$YearsBeforeDefault <- difftime(test_pruned_surv$EndDate,as.Date(as.character(test_pruned_surv$ApprovalDate), format="%m/%d/%y"), units = "days") / 365
y <- Surv(as.numeric(train_pruned_surv$YearsBeforeDefault),train_pruned_surv$status)
fit = cv.glmnet(data.matrix(train_surv_indep), y, family="cox")
fit$lambda.1se
plot(fit)
cox_model <- glmnet(data.matrix(train_surv_indep), y, family="cox", lambda = fit$lambda.1se)
coef(cox_model)
indep_surv_vars = !(names(train_pruned_surv) %in% c("ApprovalFiscalYear", "ApprovalDate", "ChargeOffDate", "defaulted", "status", "EndDate", "YearsBeforeDefault"))
train_surv_indep <- train_pruned_surv[,indep_surv_vars]
test_surv_indep <- test_pruned_surv[,indep_surv_vars]
train_pruned_surv$EndDate <- as.Date(train_pruned_surv$ChargeOffDate, format="%m/%d/%y")
train_pruned_surv$status <- train_pruned_surv$defaulted
train_pruned_surv$EndDate[which(train_pruned_surv$status == 0)] <- as.Date('12/31/14', format="%m/%d/%y")
train_pruned_surv$YearsBeforeDefault <- difftime(train_pruned_surv$EndDate,as.Date(as.character(train_pruned_surv$ApprovalDate), format="%m/%d/%y"), units = "days") / 365
test_pruned_surv$EndDate <- as.Date(test_pruned_surv$ChargeOffDate, format="%m/%d/%y")
test_pruned_surv$status <- test_pruned_surv$defaulted
test_pruned_surv$EndDate[which(test_pruned_surv$status == 0)] <- as.Date('12/31/14', format="%m/%d/%y")
test_pruned_surv$YearsBeforeDefault <- difftime(test_pruned_surv$EndDate,as.Date(as.character(test_pruned_surv$ApprovalDate), format="%m/%d/%y"), units = "days") / 365
y <- Surv(as.numeric(train_pruned_surv$YearsBeforeDefault),train_pruned_surv$status)
fit = cv.glmnet(data.matrix(train_surv_indep), y, family="cox")
plot(fit)
drops_surv <- c("Program", "BorrName","BorrStreet","BorrCity","BorrZip","CDC_Name","CDC_Street","CDC_City","CDC_Zip","ThirdPartyLender_Name","ThirdPartyLender_City","ThirdPartyLender_State","ThirdPartyDollars","Delivery Method","ProjectCounty","NaicsDescription","BorrState","CDC_State","ProjectState","LoanStatus","subpgmdesc","NaicsCode","InitialInterestRate")
train_pruned_surv <- train[,!(names(train) %in% drops_surv)]
test_pruned_surv <- test[,!(names(test) %in% drops_surv)]
indep_surv_vars = !(names(train_pruned_surv) %in% c("ApprovalFiscalYear", "ApprovalDate", "ChargeOffDate", "defaulted", "status", "EndDate", "YearsBeforeDefault"))
train_surv_indep <- train_pruned_surv[,indep_surv_vars]
test_surv_indep <- test_pruned_surv[,indep_surv_vars]
#format the data for the the survival analysis
train_pruned_surv$EndDate <- as.Date(train_pruned_surv$ChargeOffDate, format="%m/%d/%y")
train_pruned_surv$status <- train_pruned_surv$defaulted
train_pruned_surv$EndDate[which(train_pruned_surv$status == 0)] <- as.Date('12/31/14', format="%m/%d/%y")
train_pruned_surv$YearsBeforeDefault <- difftime(train_pruned_surv$EndDate,as.Date(as.character(train_pruned_surv$ApprovalDate), format="%m/%d/%y"), units = "days") / 365
test_pruned_surv$EndDate <- as.Date(test_pruned_surv$ChargeOffDate, format="%m/%d/%y")
test_pruned_surv$status <- test_pruned_surv$defaulted
test_pruned_surv$EndDate[which(test_pruned_surv$status == 0)] <- as.Date('12/31/14', format="%m/%d/%y")
test_pruned_surv$YearsBeforeDefault <- difftime(test_pruned_surv$EndDate,as.Date(as.character(test_pruned_surv$ApprovalDate), format="%m/%d/%y"), units = "days") / 365
y <- Surv(as.numeric(train_pruned_surv$YearsBeforeDefault),train_pruned_surv$status)
#fit the cox regression model with L1-regularization
fit = cv.glmnet(data.matrix(train_surv_indep), y, family="cox")
plot(fit)
cox_model <- glmnet(data.matrix(train_surv_indep), y, family="cox", lambda = fit$lambda.1se)
mydata <- read.csv("SBA_Loan_data.csv")
# Making new column for default status
mydata$defaulted <- mydata$LoanStatus == "CHGOFF"
#take out status=EXEMPT and status=CANCLD
mydata <- subset(mydata, LoanStatus!="EXEMPT"&LoanStatus!="CANCLD"&!is.na(BusinessType))
#find loans where term is (not) yearly
mydata$TermYearly <- mydata$TermInMonths%%12 == 0
#find duplicate borrowers
n_occur <- data.frame(table(mydata$BorrName))
n_occur <- n_occur[n_occur$Freq > 1,]
mydata$IsDuplicateBorrower <- mydata$BorrName %in% n_occur[,1]
#Merge with Housing Price Index data from FHFA (works!)
hpi_data <- read.table("HPI_PO_state.txt", header=TRUE, sep="\t")
names(hpi_data)[names(hpi_data)=="index_sa"] <- "HousingPriceIndex"
hpi.badcols <- c("Warning","index_nsa", "qtr")
hpi_data <- subset(hpi_data, qtr==4)
hpi_data <- hpi_data[,-which(names(hpi_data) %in% hpi.badcols)]
mydata <- merge(x=mydata, y=hpi_data, by.x=c("BorrState","ApprovalFiscalYear"), by.y=c("state","yr"))
#Merge with State Unemployment Rate data from BLS
unemp_data <- read.table("State_level_unemployment_rate_Monthly.txt", header=TRUE, sep="\t")
unemp_data_subset <- unemp_data[grep("-12-01", unemp_data$DATE), ]
unemp_data_subset$DATE <- gsub("-12-01", "", unemp_data_subset$DATE)
names(unemp_data_subset) <- gsub("UR","",names(unemp_data_subset))
#splice unemployment rate data into mydata table (works)
unemp_data_subset <- unemp_data_subset[,!(names(unemp_data_subset) %in% c("DATE"))]
temp_table <- data.frame(matrix(NA, nrow = 2000, ncol = 3))
i = 1
for(yr in 1:nrow(unemp_data_subset)) {
for(st in names(unemp_data_subset)) {
temp_table[i, ] = c(yr+1975,st,unemp_data_subset[yr,st])
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "UnemploymentRate"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$UnemploymentRate <- as.numeric(mydata$UnemploymentRate)
#Merge with Federal Funds Rate data from St. Louis Fed (works!)
fedfunds_data <- read.csv("fredgraph.csv")
fedfunds_data_subset <- fedfunds_data[grep("-12-01", fedfunds_data$observation_date),]
fedfunds_data_subset$observation_date <- gsub("-12-01", "", fedfunds_data_subset$observation_date)
mydata <- merge(x=mydata, y=fedfunds_data_subset, by.x="ApprovalFiscalYear", by.y="observation_date")
#Merge with Median Household Income data from US Census Bureau (works!)
household_income_data <- read.csv("medianhhincome.csv", header=TRUE)
names(household_income_data) <- gsub("X","",names(household_income_data))
household_mat <- as.matrix(household_income_data)
temp_table <- data.frame(matrix(NA, nrow = 1250, ncol = 3))
i = 1
for(yr in 2:ncol(household_mat)) {
for(st in 1:nrow(household_mat)-1) {
temp_table[i, ] = c(2016-yr,household_mat[st,1],as.integer(gsub(",","",household_mat[st,yr])))
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "HouseholdIncome"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$HouseholdIncome <- as.numeric(mydata$HouseholdIncome)
#Merge data with S&P returns, VIX level, 3-month and 10-month T-bill
sp_data <- read.csv("SP-data.csv")
mydata <- merge(x=mydata, y=sp_data, by.x="ApprovalFiscalYear", by.y="Year")
#Merge data with additional data from Cameron's research:
addl_data <- read.csv("Addl_Data_Selected.csv")
addl_data$Euro.USD <- NULL
addl_data$X10.yrSwap <- NULL
addl_data$Case.Shiller <- NULL
##CREATE DUMMY VARIABLES TO INDICATE MISSING DATA. OR ELSE
addl_data$StockMktTurnover_China <- NULL
addl_data$BAML_HY_Adj_Sprd <- NULL
addl_data$DisposableIncome <- NULL
mydata <- merge(x=mydata, y=addl_data, by.x="ApprovalFiscalYear", by.y="Year")
mydata$HousingPriceIndex <- mydata$HousingPriceIndex - mean(mydata$HousingPriceIndex)
mydata$HousingPriceIndex <- mydata$HousingPriceIndex / sd(mydata$HousingPriceIndex)
mydata$HouseholdIncome <- mydata$HouseholdIncome - mean(mydata$HouseholdIncome)
mydata$HouseholdIncome <- mydata$HouseholdIncome / sd(mydata$HouseholdIncome)
mydata$PublicDebt.GDP <- mydata$PublicDebt.GDP - mean(mydata$PublicDebt.GDP)
mydata$PublicDebt.GDP <- mydata$PublicDebt.GDP / sd(mydata$PublicDebt.GDP)
mydata$IndustrialProduction <- mydata$IndustrialProduction - mean(mydata$IndustrialProduction)
mydata$IndustrialProduction <- mydata$IndustrialProduction / sd(mydata$IndustrialProduction)
mydata$CPI_Index <- mydata$CPI_Index - mean(mydata$CPI_Index)
mydata$CPI_Index <- mydata$CPI_Index / sd(mydata$CPI_Index)
mydata$GrossApproval <- log(mydata$GrossApproval)
mydata$GrossApproval <- mydata$GrossApproval - mean(mydata$GrossApproval)
mydata$GrossApproval <- mydata$GrossApproval / sd(mydata$GrossApproval)
set.seed(100)
mixed.set <- mydata[sample(nrow(mydata)),]
train <- mixed.set[1:38346,]
test <- mixed.set[38346:53352,]
drops <- c("Program", "BorrName","BorrStreet","BorrCity","BorrZip","CDC_Name","CDC_Street","CDC_City","CDC_Zip","ThirdPartyLender_Name","ThirdPartyLender_City","ThirdPartyLender_State","ThirdPartyDollars","Delivery Method","ProjectCounty","ApprovalDate","ChargeOffDate","NaicsDescription","BorrState","CDC_State","ProjectState","LoanStatus","subpgmdesc","NaicsCode","InitialInterestRate")
train_pruned <- train[,!(names(train) %in% drops)]
test_pruned <- test[,!(names(test) %in% drops)]
