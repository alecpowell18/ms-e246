1 +2
require(class)
require(foreign)
install.packages("class")
install.packages("ROCR")
install.packages("e1071")
install.packages("FSelector")
install.packages("foreign")
install.packages("arules")
setwd('ms-e246')
mydata <- read.csv("SBA_Loan_data.csv")
mydata$defaulted <- mydata$GrossChargeOffAmount > 0
mydata <- subset(mydata, LoanStatus!="EXEMPT"&LoanStatus!="CANCLD"&!is.na(BusinessType))
mydata$TermYearly <- mydata$TermInMonths%%12 == 0
n_occur <- data.frame(table(mydata$BorrName))
n_occur <- n_occur[n_occur$Freq > 1,]
mydata$IsDuplicateBorrower <- mydata$BorrName %in% n_occur[,1]
hpi_data <- read.table("HPI_PO_state.txt", header=TRUE, sep="\t")
names(hpi_data)[names(hpi_data)=="index_sa"] <- "HousingPriceIndex"
hpi.badcols <- c("Warning","index_nsa", "qtr")
hpi_data <- subset(hpi_data, qtr==4)
hpi_data <- hpi_data[,-which(names(hpi_data) %in% hpi.badcols)]
mydata <- merge(x=mydata, y=hpi_data, by.x=c("BorrState","ApprovalFiscalYear"), by.y=c("state","yr"))
#Merge with State Unemployment Rate data from BLS
unemp_data <- read.table("State_level_unemployment_rate_Monthly.txt", header=TRUE, sep="\t")
unemp_data_subset <- unemp_data[grep("-12-01", unemp_data$DATE), ]
unemp_data_subset$DATE <- gsub("-12-01", "", unemp_data_subset$DATE)
names(unemp_data_subset) <- gsub("UR","",names(unemp_data_subset))
#splice unemployment rate data into mydata table (works)
unemp_data_subset <- unemp_data_subset[,!(names(unemp_data_subset) %in% c("DATE"))]
temp_table <- data.frame(matrix(NA, nrow = 2000, ncol = 3))
i = 1
for(yr in 1:nrow(unemp_data_subset)) {
for(st in names(unemp_data_subset)) {
temp_table[i, ] = c(yr+1975,st,unemp_data_subset[yr,st])
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "UnemploymentRate"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$UnemploymentRate <- as.numeric(mydata$UnemploymentRate)
#Merge with Federal Funds Rate data from St. Louis Fed (works!)
fedfunds_data <- read.csv("fredgraph.csv")
fedfunds_data_subset <- fedfunds_data[grep("-12-01", fedfunds_data$observation_date),]
fedfunds_data_subset$observation_date <- gsub("-12-01", "", fedfunds_data_subset$observation_date)
mydata <- merge(x=mydata, y=fedfunds_data_subset, by.x="ApprovalFiscalYear", by.y="observation_date")
#Merge with Median Household Income data from US Census Bureau (works!)
household_income_data <- read.csv("medianhhincome.csv", header=TRUE)
names(household_income_data) <- gsub("X","",names(household_income_data))
household_mat <- as.matrix(household_income_data)
temp_table <- data.frame(matrix(NA, nrow = 1250, ncol = 3))
i = 1
for(yr in 2:ncol(household_mat)) {
for(st in 1:nrow(household_mat)-1) {
temp_table[i, ] = c(2016-yr,household_mat[st,1],as.integer(gsub(",","",household_mat[st,yr])))
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "HouseholdIncome"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$HouseholdIncome <- as.numeric(mydata$HouseholdIncome)
#Merge data with S&P returns, VIX level, 3-month and 10-month T-bill
sp_data <- read.csv("SP-data.csv")
mydata <- merge(x=mydata, y=sp_data, by.x="ApprovalFiscalYear", by.y="Year")
#Merge data with additional data from Cameron's research:
addl_data <- read.csv("Addl_Data_Selected.csv")
addl_data$Euro.USD <- NULL
addl_data$X10.yrSwap <- NULL
addl_data$Case.Shiller <- NULL
##CREATE DUMMY VARIABLES TO INDICATE MISSING DATA. OR ELSE
addl_data$StockMktTurnover_China <- NULL
addl_data$BAML_HY_Adj_Sprd <- NULL
addl_data$DisposableIncome <- NULL
mydata <- merge(x=mydata, y=addl_data, by.x="ApprovalFiscalYear", by.y="Year")
set.seed(100)
mixed.set <- mydata[sample(nrow(mydata)),]
train <- mixed.set[1:37397,]
test <- mixed.set[38365:54807,]
#uninteresting variables not used in our model analysis
drops <- c("Program", "BorrName","BorrStreet","BorrCity","BorrZip","CDC_Name","CDC_Street","CDC_City","CDC_Zip","ThirdPartyLender_Name","ThirdPartyLender_City","ThirdPartyLender_State","ThirdPartyDollars","Delivery Method","ProjectCounty","ApprovalDate","ChargeOffDate","NaicsDescription","BorrState","CDC_State","ProjectState","LoanStatus","subpgmdesc","NaicsCode","InitialInterestRate")
train_pruned <- train[,!(names(train) %in% drops)]
test_pruned <- test[,!(names(test) %in% drops)]
save.image("/afs/.ir.stanford.edu/users/f/f/ffan9/ms-e246/dataFormatted.RData")
set.seed(2123)
# Produce a Lasso CV fit
lasso.cv <- cv.glmnet(x=as.matrix(train_indep), y=train_pruned$defaulted)
plot(lasso.cv)
# Use the 1 standard-error rule to pick lambda
lasso.cv$lambda.1se
library(glmnet)
# Control randomness in Lasso CV fit
set.seed(2123)
# Produce a Lasso CV fit
lasso.cv <- cv.glmnet(x=as.matrix(train_indep), y=train_pruned$defaulted)
plot(lasso.cv)
# Use the 1 standard-error rule to pick lambda
lasso.cv$lambda.1se
library(glmnet)
# Control randomness in Lasso CV fit
set.seed(2123)
# Produce a Lasso CV fit
lasso.cv <- cv.glmnet(x=as.matrix(train_indep), y=train_pruned$defaulted)
plot(lasso.cv)
# Use the 1 standard-error rule to pick lambda
lasso.cv$lambda.1se
indepVars <- !(names(train_pruned) %in% c("defaulted", "GrossChargeOffAmount"))
train_indep <- train_pruned[, indepVars]
test_indep <- test_pruned[, indepVars]
set.seed(2123)
# Produce a Lasso CV fit
lasso.cv <- cv.glmnet(x=as.matrix(train_indep), y=train_pruned$defaulted)
plot(lasso.cv)
# Use the 1 standard-error rule to pick lambda
lasso.cv$lambda.1se
View(train_indep)
set.seed(2123)
# Produce a Lasso CV fit
lasso.cv <- cv.glmnet(x=data.matrix(train_indep), y=train_pruned$defaulted)
plot(lasso.cv)
# Use the 1 standard-error rule to pick lambda
lasso.cv$lambda.1se
# Extract the Lasso models fit to the full training set
lasso.models <- lasso.cv$glmnet.fit
# Identify which model is associated with the selected tuning parameter
selected.index <- which(lasso.models$lambda == lasso.cv$lambda.1se)
# Display the predictors with non-zero coefficients in the selected model
colnames(train_indep)[lasso.models$beta[,selected.index] != 0]
length(colnames(train_indep)[lasso.models$beta[,selected.index] != 0])
dim(train_pruned)
log.reg.l1 <- cv.glmnet(data.matrix(train_indep),
train_pruned$defaulted,
family="binomial", lambda = grid)
grid=10^seq(2,-6,length=100)
log.reg.l1 <- cv.glmnet(data.matrix(train_indep),
train_pruned$defaulted,
family="binomial", lambda = grid)
grid=10^seq(0,-10,length=100)
set.seed(2123)
lasso.cv <- cv.glmnet(x=data.matrix(train_indep), y=train_pruned$defaulted, lambda=grid)
plot(lasso.cv)
grid=10^seq(0,-200,length=100)
grid=10^seq(0,-20,length=100)
set.seed(2123)
lasso.cv <- cv.glmnet(x=data.matrix(train_indep), y=train_pruned$defaulted, lambda=grid)
plot(lasso.cv)
set.seed(2123)
lasso.cv <- cv.glmnet(x=data.matrix(train_indep), y=train_pruned$defaulted)
plot(lasso.cv)
lasso.cv$lambda.1se
lasso.models <- lasso.cv$glmnet.fit
# Identify which model is associated with the selected tuning parameter
selected.index <- which(lasso.models$lambda == lasso.cv$lambda.1se)
# Display the predictors with non-zero coefficients in the selected model
colnames(train_indep)[lasso.models$beta[,selected.index] != 0]
log.reg.l1 <- cv.glmnet(data.matrix(train_indep),
train_pruned$defaulted,
family="binomial")
set.seed(2123)
lasso.cv <- cv.glmnet(x=data.matrix(train_indep), y=train_pruned$defaulted, family = "binomial")
plot(lasso.cv)
plot(lasso.cv)
lasso.cv$lambda.1se
lasso.models <- lasso.cv$glmnet.fit
# Identify which model is associated with the selected tuning parameter
selected.index <- which(lasso.models$lambda == lasso.cv$lambda.1se)
# Display the predictors with non-zero coefficients in the selected model
colnames(train_indep)[lasso.models$beta[,selected.index] != 0]
lasso.test.pred <- predict(lasso.models, data.matrix(test_indep),
s = lasso.models$lambda[selected.index])
sqrt(mean((lasso.test.pred - test_pruned$defaulted)^2))
save.image("/afs/.ir.stanford.edu/users/f/f/ffan9/ms-e246/dataFormatted.RData")
savehistory("/afs/.ir.stanford.edu/users/f/f/ffan9/ms-e246/20160302History.Rhistory")
load("//afs/ir.stanford.edu/users/f/f/ffan9/ms-e246/dataFormatted.RData")
mydata <- read.csv("SBA_Loan_data.csv")
rbern(1, .5)
library(LaplacesDemon)
install.packages("LaplacesDemon")
library(LaplacesDemon)
library(stats)
rbinom(1, 1, .5)
rbinom(1, 1, .5)
rbinom(1, 1, .5)
rbinom(1, 1, .5)
rbinom(1, 2, .5)
rbinom(1, 2, .5)
rbinom(1, 2, .5)
rbinom(1, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 2, .5)
rbinom(5, 100, .5)
rbinom(5, 100, .5)
rbinom(5, 100, .5)
rbinom(5, 100, .5)
rbinom(5, 100, .5)
rbinom(5, 100, .5)
rbinom(5, 2, .5)
rbinom(5, 100, .5)
rbinom(5, 2, .5)
rbinom(5, 100, .5)
rbinom(5, 2, .5)
rbinom(5, 100, .5)
a <- c(3,4,5,6,7)
a <- c(.3,.4,.5,.6)
rbinom(5, 100, a)
rbinom(1, 1, a)
rbinom(1, 1, a)
rbinom(1, 1, a)
rbinom(1, 1, a)
rbinom(5, 100, a)
rbinom(1, 1, a)
rbinom(5, 100, a)
rbinom(5, 100, a)
rbinom(1, 1, a)
rbinom(1, 1, a)
a
sum < - c(0.0,0.0,0.0,0.0)
for (i in 1:5000){
sum += rbinom(4,1,a)
}
sum <- c(0.0,0.0,0.0,0.0)
for (i in 1:5000){
sum += rbinom(4,1,a)
}
sum <- c(0.0,0.0,0.0,0.0)
for (i in 1:5000){
sum = sum + rbinom(4,1,a)
}
sum
a
sum/5000
1 == 'TRUE'
1 == TRUE
1 == T
mydata <- read.csv("SBA_Loan_data.csv")
mydata$defaulted <- mydata$GrossChargeOffAmount > 0
#take out status=EXEMPT and status=CANCLD
mydata <- subset(mydata, LoanStatus!="EXEMPT"&LoanStatus!="CANCLD"&!is.na(BusinessType))
mydata$TermYearly <- mydata$TermInMonths%%12 == 0
#find duplicate borrowers
n_occur <- data.frame(table(mydata$BorrName))
n_occur <- n_occur[n_occur$Freq > 1,]
mydata$IsDuplicateBorrower <- mydata$BorrName %in% n_occur[,1]
#Merge with Housing Price Index data from FHFA (works!)
hpi_data <- read.table("HPI_PO_state.txt", header=TRUE, sep="\t")
names(hpi_data)[names(hpi_data)=="index_sa"] <- "HousingPriceIndex"
hpi.badcols <- c("Warning","index_nsa", "qtr")
hpi_data <- subset(hpi_data, qtr==4)
mydata <- merge(x=mydata, y=hpi_data, by.x=c("BorrState","ApprovalFiscalYear"), by.y=c("state","yr"))
hpi_data <- hpi_data[,-which(names(hpi_data) %in% hpi.badcols)]
#Merge with State Unemployment Rate data from BLS
unemp_data <- read.table("State_level_unemployment_rate_Monthly.txt", header=TRUE, sep="\t")
unemp_data_subset <- unemp_data[grep("-12-01", unemp_data$DATE), ]
unemp_data_subset$DATE <- gsub("-12-01", "", unemp_data_subset$DATE)
names(unemp_data_subset) <- gsub("UR","",names(unemp_data_subset))
#splice unemployment rate data into mydata table (works)
unemp_data_subset <- unemp_data_subset[,!(names(unemp_data_subset) %in% c("DATE"))]
temp_table <- data.frame(matrix(NA, nrow = 2000, ncol = 3))
i = 1
for(yr in 1:nrow(unemp_data_subset)) {
for(st in names(unemp_data_subset)) {
temp_table[i, ] = c(yr+1975,st,unemp_data_subset[yr,st])
i=i+1
}
}
names(temp_table)[names(temp_table)=="X1"] <- "YR"
names(temp_table)[names(temp_table)=="X2"] <- "ST"
names(temp_table)[names(temp_table)=="X3"] <- "UnemploymentRate"
mydata <- merge(x=mydata, y=temp_table, by.x=c("ApprovalFiscalYear","BorrState"), by.y=c("YR","ST"))
mydata$UnemploymentRate <- as.numeric(mydata$UnemploymentRate)
#Merge with Federal Funds Rate data from St. Louis Fed (works!)
fedfunds_data <- read.csv("fredgraph.csv")
fedfunds_data_subset <- fedfunds_data[grep("-12-01", fedfunds_data$observation_date),]
fedfunds_data_subset$observation_date <- gsub("-12-01", "", fedfunds_data_subset$observation_date)
mydata <- merge(x=mydata, y=fedfunds_data_subset, by.x="ApprovalFiscalYear", by.y="observation_date")
?qbinom
qbinom(c(.3,.6), 10, .5)
qbinom(c(.3,.6), 10, .5)
qbinom(c(.3,.6), 10, .5)
qbinom(c(.3,.6), 10, .5)
qbinom(c(.3,.6), 10, .5)
qbinom(c(.3,.6), 10, .5)
qbinom(c(.5,1), 10, .5)
a <- qbinom(c(.025,.975), 100, .5)
a <- qbinom(c(.025,.975), 100, .5)
a <- qbinom(c(.025,.975), 1e5, .5)
a
a <- qbinom(c(.025,.975), 1e6, .5)
a
a <- qbinom(c(.025,.975), 1e6, .05)
findInterval(3, c(0,4,6,7,9))
10^3
-1:3
a <- matrix()
a[2][0] <- 9
a
a <- matrix(2,2)
a
a <- matrix((2,2),(2,2))
a <- matrix(c(0,0,0,0,0,0,0,0,0), nrow = 3)
a
a <- matrix(nrow = 3, ncol = 3)
a
library(survival)
